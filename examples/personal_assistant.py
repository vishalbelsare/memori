"""
Personal Assistant with Memori
AI assistant with conscious ingestion and intelligent memory
"""

from dotenv import load_dotenv
from litellm import completion

from memori import Memori

load_dotenv()


def main():
    print("ğŸ¤– Personal Assistant with Conscious Memory")
    print("=" * 50)

    # Create personal memory space with conscious ingestion
    personal = Memori(
        database_connect="sqlite:///personal_assistant.db",
        namespace="personal",  # Separate from work memories
        conscious_ingest=True,  # ğŸ§  Enable background analysis
        verbose=True,  # Show conscious agent activity
        openai_api_key=None,  # Uses OPENAI_API_KEY from environment
    )

    personal.enable()
    print("âœ… Personal assistant memory enabled")
    print("ğŸ§  Background conscious analysis started")
    print("ğŸ¯ Essential memories will be automatically promoted")

    # Simulate a conversation flow
    conversations = [
        {
            "context": "Establishing preferences",
            "user": "I'm a software engineer who loves Python and prefers minimalist tools",
            "expected": "Remembers: Python preference, minimalist tools",
        },
        {
            "context": "Daily routine",
            "user": "I usually code in the mornings and prefer short, focused work sessions",
            "expected": "Remembers: Work schedule, focus preferences",
        },
        {
            "context": "Learning goals",
            "user": "I want to learn more about AI and machine learning this year",
            "expected": "Remembers: Learning goals for AI/ML",
        },
        {
            "context": "Applying memory - tool recommendation",
            "user": "What development tools should I use for my next project?",
            "expected": "Suggests Python tools, considers minimalist preference",
        },
        {
            "context": "Applying memory - schedule advice",
            "user": "How should I structure my learning time?",
            "expected": "Considers morning coding preference, short sessions",
        },
    ]

    for i, conv in enumerate(conversations, 1):
        print(f"\n--- Conversation {i}: {conv['context']} ---")
        print(f"You: {conv['user']}")

        response = completion(
            model="gpt-4o-mini", messages=[{"role": "user", "content": conv["user"]}]
        )

        print(f"Assistant: {response.choices[0].message.content}")
        print(f"ğŸ’¡ Expected memory: {conv['expected']}")

    print("\nğŸ¯ Conscious Memory in Action:")
    print("  âœ… Preferences automatically categorized and stored")
    print("  âœ… Essential information promoted for instant access")
    print("  âœ… Context intelligently injected based on relevance")
    print("  âœ… Personalized responses improve over time")

    # Demonstrate conscious analysis
    print("\nğŸ§  Triggering conscious analysis...")
    try:
        personal.trigger_conscious_analysis()
        essential = personal.get_essential_conversations(limit=3)
        print(f"  âœ… Analysis complete: {len(essential)} essential memories promoted")
    except Exception as e:
        print(f"  âš ï¸ Analysis requires more conversation data: {e}")

    print("\nğŸ’¾ Check 'personal_assistant.db' to see stored memories!")
    print("ğŸ”¬ Enable verbose=True to see agent activity in real-time")


if __name__ == "__main__":
    main()
